{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce503323",
   "metadata": {},
   "source": [
    "# Torch vs. ONNX\n",
    "\n",
    "Verify that the spike detection model output of braindance vs. torch vs. onnx in python is concordant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf8f40de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7293e7",
   "metadata": {},
   "source": [
    "## Load Trained Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4b0240c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate a trained model\n",
    "from braindance.core.spikedetector.model import ModelSpikeSorter\n",
    "\n",
    "# detection_model = ModelSpikeSorter.load(\"checkpoints/spikedetector/mea\")\n",
    "\n",
    "with open(\"checkpoints/spikedetector/mea/init_dict.json\", \"r\") as f:\n",
    "    init_dict = json.load(f)\n",
    "pytorch_model = ModelSpikeSorter(**init_dict)\n",
    "state_dict = torch.load(\n",
    "    \"checkpoints/spikedetector/mea/state_dict.pt\", map_location=\"cpu\"\n",
    ")\n",
    "pytorch_model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d09447e",
   "metadata": {},
   "source": [
    "## Run via Braindance\n",
    "\n",
    "Populates data/inter if debug=False\n",
    "\n",
    "```\n",
    "Saving traces:\n",
    "100%|██████████| 1/1 [00:04<00:00,  4.46s/it]\n",
    "Running detection model:\n",
    "Compiling detection model for 942 elecs ...\n",
    "Cannot compile detection model with torch_tensorrt because cannot load torch_tensorrt. Skipping NVIDIA compilation\n",
    "Allocating disk space to save model traces and outputs ...\n",
    "Inference scaling: 0.3761194029850746\n",
    "Running model ...\n",
    "100%|██████████| 832/832 [09:36<00:00,  1.44it/s]\n",
    "Detecting sequences\n",
    "100%|██████████| 942/942 [00:04<00:00, 211.68it/s]\n",
    "Detected 10 preliminary propagation sequences\n",
    "Extracting sequences' detections, intervals, and amplitudes\n",
    "\n",
    "100%|██████████| 10/10 [00:02<00:00,  4.03it/s]\n",
    "8 clusters remain after filtering\n",
    "Reassigning spikes to preliminary propagation sequences\n",
    "Initializing ...\n",
    "Sorting recording\n",
    "100%|██████████| 1000/1000 [00:00<00:00, 3377.24it/s]\n",
    "Extracting sequences' detections, intervals, and amplitudes\n",
    "\n",
    "100%|██████████| 7/7 [00:02<00:00,  2.80it/s]\n",
    "7 clusters remain after filtering\n",
    "Merging preliminary propagation sequences - first round\n",
    "\n",
    "100%|██████████| 7/7 [00:02<00:00,  3.14it/s]\n",
    "7 sequences after first merging\n",
    "Merging preliminary propagation sequences - second round ...\n",
    "\n",
    "RT-Sort detected 7 sequences\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a958efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping saving scaled traces because file scaled_traces.npy already exists and debug=True\n",
      "Skipping running detection model because file model_outputs.npy already exists and debug=True\n",
      "Skipping detecting preliminary propagation sequences because file all_clusters.pickle already exists and debug=True\n",
      "Skipping reassigning spikes because file all_clusters_reassigned.pickle already exists and debug=True\n",
      "Merging preliminary propagation sequences - first round\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  0%|          | 0/7 [00:11<?, ?it/s]  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/rcurrie/rtsort-web/venv/lib/python3.11/site-packages/debugpy/_vendored/pydevd/pydevd.py\", line 3020, in settrace\n",
      "  File \"/Users/rcurrie/rtsort-web/venv/lib/python3.11/site-packages/debugpy/_vendored/pydevd/pydevd.py\", line 3020, in settrace\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/rcurrie/rtsort-web/venv/lib/python3.11/site-packages/debugpy/_vendored/pydevd/pydevd.py\", line 3020, in settrace\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/rcurrie/rtsort-web/venv/lib/python3.11/site-packages/debugpy/_vendored/pydevd/pydevd.py\", line 3020, in settrace\n",
      "  File \"/Users/rcurrie/rtsort-web/venv/lib/python3.11/site-packages/debugpy/_vendored/pydevd/pydevd.py\", line 3020, in settrace\n",
      "  File \"/Users/rcurrie/rtsort-web/venv/lib/python3.11/site-packages/debugpy/_vendored/pydevd/pydevd.py\", line 3020, in settrace\n",
      "  File \"/Users/rcurrie/rtsort-web/venv/lib/python3.11/site-packages/debugpy/_vendored/pydevd/pydevd.py\", line 3020, in settrace\n",
      "\n",
      "        _locked_settrace(_locked_settrace(\n",
      "\n",
      "      File \"/Users/rcurrie/rtsort-web/venv/lib/python3.11/site-packages/debugpy/_vendored/pydevd/pydevd.py\", line 3129, in _locked_settrace\n",
      "  File \"/Users/rcurrie/rtsort-web/venv/lib/python3.11/site-packages/debugpy/_vendored/pydevd/pydevd.py\", line 3129, in _locked_settrace\n",
      "_locked_settrace(\n",
      "  File \"/Users/rcurrie/rtsort-web/venv/lib/python3.11/site-packages/debugpy/_vendored/pydevd/pydevd.py\", line 3129, in _locked_settrace\n",
      "    _locked_settrace(\n",
      "  File \"/Users/rcurrie/rtsort-web/venv/lib/python3.11/site-packages/debugpy/_vendored/pydevd/pydevd.py\", line 3129, in _locked_settrace\n",
      "    _locked_settrace(\n",
      "  File \"/Users/rcurrie/rtsort-web/venv/lib/python3.11/site-packages/debugpy/_vendored/pydevd/pydevd.py\", line 3129, in _locked_settrace\n",
      "        _locked_settrace(_locked_settrace(\n",
      "\n",
      "  File \"/Users/rcurrie/rtsort-web/venv/lib/python3.11/site-packages/debugpy/_vendored/pydevd/pydevd.py\", line 3129, in _locked_settrace\n",
      "  File \"/Users/rcurrie/rtsort-web/venv/lib/python3.11/site-packages/debugpy/_vendored/pydevd/pydevd.py\", line 3129, in _locked_settrace\n",
      "    py_db.wait_for_ready_to_run()\n",
      "    py_db.wait_for_ready_to_run()\n",
      "  File \"/Users/rcurrie/rtsort-web/venv/lib/python3.11/site-packages/debugpy/_vendored/pydevd/pydevd.py\", line 899, in wait_for_ready_to_run\n",
      "  File \"/Users/rcurrie/rtsort-web/venv/lib/python3.11/site-packages/debugpy/_vendored/pydevd/pydevd.py\", line 899, in wait_for_ready_to_run\n",
      "    py_db.wait_for_ready_to_run()\n",
      "    py_db.wait_for_ready_to_run()\n",
      "  File \"/Users/rcurrie/rtsort-web/venv/lib/python3.11/site-packages/debugpy/_vendored/pydevd/pydevd.py\", line 899, in wait_for_ready_to_run\n",
      "  File \"/Users/rcurrie/rtsort-web/venv/lib/python3.11/site-packages/debugpy/_vendored/pydevd/pydevd.py\", line 899, in wait_for_ready_to_run\n",
      "    self._py_db_command_thread_event.wait(TIMEOUT_FAST)\n",
      "    self._py_db_command_thread_event.wait(TIMEOUT_FAST)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py\", line 629, in wait\n",
      "    self._py_db_command_thread_event.wait(TIMEOUT_FAST)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py\", line 629, in wait\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py\", line 629, in wait\n",
      "    py_db.wait_for_ready_to_run()\n",
      "  File \"/Users/rcurrie/rtsort-web/venv/lib/python3.11/site-packages/debugpy/_vendored/pydevd/pydevd.py\", line 899, in wait_for_ready_to_run\n",
      "    py_db.wait_for_ready_to_run()\n",
      "  File \"/Users/rcurrie/rtsort-web/venv/lib/python3.11/site-packages/debugpy/_vendored/pydevd/pydevd.py\", line 899, in wait_for_ready_to_run\n",
      "    self._py_db_command_thread_event.wait(TIMEOUT_FAST)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py\", line 629, in wait\n",
      "    self._py_db_command_thread_event.wait(TIMEOUT_FAST)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py\", line 629, in wait\n",
      "    py_db.wait_for_ready_to_run()\n",
      "    self._py_db_command_thread_event.wait(TIMEOUT_FAST)\n",
      "  File \"/Users/rcurrie/rtsort-web/venv/lib/python3.11/site-packages/debugpy/_vendored/pydevd/pydevd.py\", line 899, in wait_for_ready_to_run\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py\", line 629, in wait\n",
      "    signaled = self._cond.wait(timeout)\n",
      "    signaled = self._cond.wait(timeout)\n",
      "    signaled = self._cond.wait(timeout)\n",
      "               signaled = self._cond.wait(timeout)\n",
      "                  signaled = self._cond.wait(timeout) \n",
      "^^^^^ ^^ ^^ ^  ^     ^ ^ ^ ^ ^ ^ ^ ^ ^     ^  ^  ^  ^  ^  ^          ^^ ^^^^^^^^^^^^^^^ ^^ ^ ^^ ^^ ^^^^^^^\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^  File \"/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py\", line 331, in wait\n",
      "^^^^^^^\n",
      "^^^^^^^^^  File \"/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py\", line 331, in wait\n",
      "^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py\", line 331, in wait\n",
      "    self._py_db_command_thread_event.wait(TIMEOUT_FAST)\n",
      "^^^  File \"/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py\", line 629, in wait\n",
      "^^^^^\n",
      "\n",
      "    signaled = self._cond.wait(timeout)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py\", line 331, in wait\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py\", line 331, in wait\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py\", line 331, in wait\n",
      "    gotit = waiter.acquire(True, timeout)\n",
      "    gotit = waiter.acquire(True, timeout)\n",
      "    gotit = waiter.acquire(True, timeout)\n",
      "                 signaled = self._cond.wait(timeout) ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^^^^^^ ^    \n",
      "  ^ ^^^^^^^^^ ^ ^ ^   ^         gotit = waiter.acquire(True, timeout) \n",
      "     ^^^^^ ^ ^ ^ ^ ^ ^^^^^ ^ ^^ ^^ ^^ ^ ^^ ^^^^^^    ^gotit = waiter.acquire(True, timeout)\n",
      "\n",
      "^    gotit = waiter.acquire(True, timeout)^\n",
      "^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      " ^^KeyboardInterrupt   ^^\n",
      " ^^^^^^^KeyboardInterrupt^^\n",
      "^ ^^ \n",
      " ^    File \"/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py\", line 331, in wait\n",
      "  ^ ^ ^ ^ ^ ^ ^^\n",
      "^ ^^^^ ^^KeyboardInterrupt ^\n",
      "^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^^^^^^^^^KeyboardInterrupt^^^^\n",
      "\n",
      "^KeyboardInterrupt^^\n",
      "^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "    gotit = waiter.acquire(True, timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py:856\u001b[39m, in \u001b[36mIMapIterator.next\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    855\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m856\u001b[39m     item = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_items\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpopleft\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    857\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n",
      "\u001b[31mIndexError\u001b[39m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbraindance\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mspikesorter\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrt_sort\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m detect_sequences\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Detect sequences in the first 5 minutes of a recording\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m rt_sort = \u001b[43mdetect_sequences\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata/MEA_rec_patch_ground_truth_cell7.raw.h5\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata/inter\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpytorch_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrecording_window_ms\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcpu\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# num_processes=1,  # Uncomment for debugging\u001b[39;49;00m\n\u001b[32m     13\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/braindance/braindance/core/spikesorter/rt_sort.py:363\u001b[39m, in \u001b[36mdetect_sequences\u001b[39m\u001b[34m(recording, inter_path, detection_model, recording_window_ms, stringent_thresh, loose_thresh, inference_scaling_numerator, ms_before, ms_after, pre_median_ms, inner_radius, outer_radius, min_elecs_for_array_noise_n, min_elecs_for_array_noise_f, min_elecs_for_seq_noise_n, min_elecs_for_seq_noise_f, min_activity_root_cocs, min_activity_hz, max_n_components_latency, min_coc_n, min_coc_p, min_extend_comp_p, elec_patience, split_coc_clusters_amps, min_amp_dist_p, max_n_components_amp, min_loose_elec_prob, min_inner_loose_detections, min_loose_detections_n, min_loose_detections_r_spikes, min_loose_detections_r_sequences, max_latency_diff_spikes, max_latency_diff_sequences, clip_latency_diff_factor, max_amp_median_diff_spikes, max_amp_median_diff_sequences, clip_amp_median_diff_factor, max_root_amp_median_std_spikes, max_root_amp_median_std_sequences, repeated_detection_overlap_time, min_seq_spikes_n, min_seq_spikes_hz, relocate_root_min_amp, relocate_root_max_latency, return_spikes, delete_inter, device, num_processes, ignore_warnings, verbose, debug)\u001b[39m\n\u001b[32m    360\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    362\u001b[39m \u001b[38;5;66;03m# Merging (happens very quickly, so don't need to dump if debug=True)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m intra_merged_clusters = \u001b[43mintra_merge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_clusters_reassigned\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    364\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(intra_merged_clusters) == \u001b[32m0\u001b[39m:  \u001b[38;5;66;03m# It should't be possible for this to be True, but just in case\u001b[39;00m\n\u001b[32m    365\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m verbose:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/braindance/braindance/core/spikesorter/rt_sort.py:2905\u001b[39m, in \u001b[36mintra_merge\u001b[39m\u001b[34m(all_clusters, params)\u001b[39m\n\u001b[32m   2903\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[32m   2904\u001b[39m         imap = tqdm(imap, total=\u001b[38;5;28mlen\u001b[39m(tasks))\n\u001b[32m-> \u001b[39m\u001b[32m2905\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclusters\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimap\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2906\u001b[39m \u001b[43m        \u001b[49m\u001b[43mintra_merged_clusters\u001b[49m\u001b[43m.\u001b[49m\u001b[43mextend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclusters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2908\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/rtsort-web/venv/lib/python3.11/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py:861\u001b[39m, in \u001b[36mIMapIterator.next\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    859\u001b[39m     \u001b[38;5;28mself\u001b[39m._pool = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    860\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m861\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cond\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    862\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    863\u001b[39m     item = \u001b[38;5;28mself\u001b[39m._items.popleft()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py:327\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[32m    326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m         \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    328\u001b[39m         gotit = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    329\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from braindance.core.spikesorter.rt_sort import detect_sequences\n",
    "\n",
    "# Detect sequences in the first 5 minutes of a recording\n",
    "rt_sort = detect_sequences(\n",
    "    \"data/MEA_rec_patch_ground_truth_cell7.raw.h5\",\n",
    "    \"data/inter\",\n",
    "    pytorch_model,\n",
    "    recording_window_ms=(0, 5 * 1000),\n",
    "    device=\"cpu\",\n",
    "    verbose=True,\n",
    "    debug=True,\n",
    "    # num_processes=1,  # Uncomment for debugging\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ac8d7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load outputs for comparison below\n",
    "scaled_traces = np.load(\"data/inter/scaled_traces.npy\")\n",
    "braindance_model_outputs = np.load(\"data/inter/model_outputs.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86793404",
   "metadata": {},
   "source": [
    "## Run via PyTorch\n",
    "\n",
    "Run using PyTorch with a simplified version of the code in braindance rtsort run_detection_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2baa4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:07<00:00,  1.40it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def run_detection_model(\n",
    "    scaled_traces,\n",
    "    model,\n",
    "    inference_scaling_numerator=12.6,\n",
    "    pre_median_frames=1000,\n",
    "    device=\"cpu\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Simplified function to run a PyTorch detection model on scaled traces using windowed computation.\n",
    "\n",
    "    Parameters:\n",
    "        scaled_traces (np.ndarray): Input data array of shape (num_channels, recording_duration).\n",
    "        model: Pre-instantiated PyTorch model with attributes sample_size, num_output_locs, input_scale.\n",
    "        inference_scaling_numerator (float): Numerator for scaling factor calculation.\n",
    "        pre_median_frames (int): Number of frames for initial median calculation.\n",
    "        device (str): Device to run the model on (\"cuda\" or \"cpu\").\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Model outputs of shape (num_channels, processed_duration).\n",
    "    \"\"\"\n",
    "    # Convert input to torch tensor\n",
    "    scaled_traces = torch.tensor(scaled_traces, device=device, dtype=torch.float16)\n",
    "\n",
    "    # Get model parameters\n",
    "    sample_size = model.sample_size\n",
    "    num_output_locs = model.num_output_locs\n",
    "    input_scale = model.input_scale\n",
    "    num_chans, rec_duration = scaled_traces.shape\n",
    "\n",
    "    # Calculate inference scaling based on initial window\n",
    "    window = (\n",
    "        scaled_traces[:, :pre_median_frames].to(torch.float32).cpu()\n",
    "    )  # Cast to float32 and move to CPU\n",
    "    if window.dtype != torch.float32:\n",
    "        raise ValueError(\n",
    "            f\"Window tensor dtype is {window.dtype}, expected torch.float32\"\n",
    "        )\n",
    "    iqrs = torch.quantile(window, 0.75, dim=1) - torch.quantile(window, 0.25, dim=1)\n",
    "    median_iqr = torch.median(iqrs)\n",
    "    inference_scaling = (\n",
    "        inference_scaling_numerator / median_iqr if median_iqr != 0 else 1\n",
    "    )\n",
    "\n",
    "    # Define windows for processing\n",
    "    all_start_frames = list(range(0, rec_duration - sample_size + 1, num_output_locs))[\n",
    "        0:10\n",
    "    ]\n",
    "    output_duration = rec_duration - sample_size + 1\n",
    "    outputs_all = torch.zeros(\n",
    "        (num_chans, output_duration), device=device, dtype=torch.float16\n",
    "    )\n",
    "\n",
    "    # Process each window\n",
    "    with torch.no_grad():\n",
    "        for start_frame in tqdm(all_start_frames):\n",
    "            # Extract window\n",
    "            traces_torch = scaled_traces[:, start_frame : start_frame + sample_size]\n",
    "\n",
    "            # Subtract median for baseline correction\n",
    "            traces_torch = (\n",
    "                traces_torch - torch.median(traces_torch, dim=1, keepdim=True).values\n",
    "            )\n",
    "\n",
    "            # Run model on window and store output\n",
    "            outputs = model.model(\n",
    "                traces_torch[:, None, :] * input_scale * inference_scaling\n",
    "            )\n",
    "            outputs_all[:, start_frame : start_frame + num_output_locs] = outputs\n",
    "\n",
    "    return outputs_all.cpu()\n",
    "\n",
    "\n",
    "pytorch_model_outputs = run_detection_model(\n",
    "    scaled_traces=scaled_traces, model=pytorch_model, device=\"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4632784c",
   "metadata": {},
   "source": [
    "## Compare Braindance to PyTorch Model Outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e513300d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.True_"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We only did 10 frames above, so we can check the first 10 frames\n",
    "end = 10 * pytorch_model.num_output_locs\n",
    "np.isclose(\n",
    "    braindance_model_outputs[:, 0:end],\n",
    "    pytorch_model_outputs.detach().numpy()[:, 0:end],\n",
    "    rtol=1e-6,\n",
    ").all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728ffffb",
   "metadata": {},
   "source": [
    "# Export to .onnx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7913d4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "\n",
    "pytorch_model.model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Convert all parameters to float32\n",
    "# model = pytorch_model.model.float()  # This casts all parameters to torch.float32\n",
    "\n",
    "torch.onnx.export(\n",
    "    pytorch_model.model,\n",
    "    torch.zeros(1, 1, pytorch_model.sample_size, dtype=torch.float16),\n",
    "    str(\"public/models/detect-mea.onnx\"),\n",
    "    input_names=[\"input\"],\n",
    "    output_names=[\"output\"],\n",
    "    dynamic_axes={\n",
    "        \"input\": {0: \"batch_size\", 2: \"sequence_length\"},\n",
    "        \"output\": {0: \"batch_size\", 2: \"sequence_length\"},\n",
    "    },\n",
    "    opset_version=12,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4853f8",
   "metadata": {},
   "source": [
    "## Run via PyTorch and ONNX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9af9511",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:08<00:00,  1.19it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import onnxruntime\n",
    "\n",
    "\n",
    "def run_detection_model_onnx(\n",
    "    scaled_traces,\n",
    "    model,\n",
    "    ort_session,\n",
    "    inference_scaling_numerator=12.6,\n",
    "    pre_median_frames=1000,\n",
    "    device=\"cpu\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Simplified function to run a PyTorch detection model on scaled traces using windowed computation.\n",
    "\n",
    "    Parameters:\n",
    "        scaled_traces (np.ndarray): Input data array of shape (num_channels, recording_duration).\n",
    "        model: Pre-instantiated PyTorch model with attributes sample_size, num_output_locs, input_scale.\n",
    "        inference_scaling_numerator (float): Numerator for scaling factor calculation.\n",
    "        pre_median_frames (int): Number of frames for initial median calculation.\n",
    "        device (str): Device to run the model on (\"cuda\" or \"cpu\").\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Model outputs of shape (num_channels, processed_duration).\n",
    "    \"\"\"\n",
    "    # Convert input to torch tensor\n",
    "    scaled_traces = torch.tensor(scaled_traces, device=device, dtype=torch.float16)\n",
    "\n",
    "    # Get model parameters\n",
    "    sample_size = model.sample_size\n",
    "    num_output_locs = model.num_output_locs\n",
    "    input_scale = model.input_scale\n",
    "    num_chans, rec_duration = scaled_traces.shape\n",
    "\n",
    "    # Calculate inference scaling based on initial window\n",
    "    window = (\n",
    "        scaled_traces[:, :pre_median_frames].to(torch.float32).cpu()\n",
    "    )  # Cast to float32 and move to CPU\n",
    "    if window.dtype != torch.float32:\n",
    "        raise ValueError(\n",
    "            f\"Window tensor dtype is {window.dtype}, expected torch.float32\"\n",
    "        )\n",
    "    iqrs = torch.quantile(window, 0.75, dim=1) - torch.quantile(window, 0.25, dim=1)\n",
    "    median_iqr = torch.median(iqrs)\n",
    "    inference_scaling = (\n",
    "        inference_scaling_numerator / median_iqr if median_iqr != 0 else 1\n",
    "    )\n",
    "\n",
    "    # Define windows for processing\n",
    "    all_start_frames = list(range(0, rec_duration - sample_size + 1, num_output_locs))[\n",
    "        0:10\n",
    "    ]\n",
    "    output_duration = rec_duration - sample_size + 1\n",
    "    outputs_all = np.zeros((num_chans, output_duration), dtype=np.float16)\n",
    "\n",
    "    # Process each window\n",
    "    with torch.no_grad():\n",
    "        for start_frame in tqdm(all_start_frames):\n",
    "            # Extract window\n",
    "            traces_torch = scaled_traces[:, start_frame : start_frame + sample_size]\n",
    "\n",
    "            # Subtract median for baseline correction\n",
    "            traces_torch = (\n",
    "                traces_torch - torch.median(traces_torch, dim=1, keepdim=True).values\n",
    "            )\n",
    "\n",
    "            # Run model on window and store output\n",
    "            input_frame = traces_torch[:, None, :] * input_scale * inference_scaling\n",
    "\n",
    "            pytorch_outputs = model.model(input_frame)\n",
    "            onnx_outputs = ort_session.run(\n",
    "                [\"output\"],\n",
    "                {\"input\": input_frame.numpy()},\n",
    "            )[0]\n",
    "\n",
    "            match = np.isclose(\n",
    "                pytorch_outputs.detach().numpy(),\n",
    "                onnx_outputs,\n",
    "                rtol=1e-2,\n",
    "            ).all()\n",
    "            assert match, \"PyTorch and ONNX outputs do not match!\"\n",
    "\n",
    "            outputs_all[:, start_frame : start_frame + num_output_locs] = (\n",
    "                onnx_outputs.squeeze()\n",
    "            )\n",
    "\n",
    "    return outputs_all\n",
    "\n",
    "\n",
    "ort_session = onnxruntime.InferenceSession(\"public/models/detect-mea.onnx\")\n",
    "\n",
    "onnx_model_outputs = run_detection_model_onnx(\n",
    "    scaled_traces=scaled_traces,\n",
    "    model=pytorch_model,\n",
    "    ort_session=ort_session,\n",
    "    device=\"cpu\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ccbd60b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.True_"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We only did 20 frames above, so we can check the first 20 frames\n",
    "end = 10 * pytorch_model.num_output_locs\n",
    "np.isclose(\n",
    "    braindance_model_outputs[:, 0:end],\n",
    "    onnx_model_outputs[:, 0:end],\n",
    "    rtol=1e-2,\n",
    ").all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
